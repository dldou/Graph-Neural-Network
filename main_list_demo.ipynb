{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing same but with list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, Dataset, DataLoader\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "import networkx as nx\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "\n",
    "from dataset_list import *\n",
    "from dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing CustomizableMNIST...\n",
      "Training set\n",
      "Init done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "train_set = CustomizableMNIST(root='./data', train=True, download=True)\n",
    "\n",
    "val_set_ratio = 0.2\n",
    "shuffle = True\n",
    "batch_size = 32\n",
    "\n",
    "train_loader, valid_loader = split_and_shuffle_data(train_set, val_set_ratio, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dldou/anaconda3/lib/python3.9/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "filename = 'graph_collection_dataset.pkl'\n",
    "#graph_collection = compute_graph_collection_and_save_pickle_file(train_set, filename, ratio=0.01)\n",
    "graph_collection_dataset = load_graph_collection_from_pickle_file(filename) \n",
    "graph_train_dataset = GraphDataset(graph_collection_dataset)\n",
    "dataloader = GraphDataLoader(graph_collection_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_model(nn.Module):\n",
    "\n",
    "    def __init__(self, num_layer, num_in_features=1, num_out_features=1):\n",
    "        super(GCN_model, self).__init__()\n",
    "        self.fc = nn.Linear(in_features=num_in_features, out_features=num_out_features)\n",
    "    \n",
    "    def forward(self, list_of_graph):\n",
    "        # unpack data\n",
    "        nodes_feat_list, edges_index_list, graph_label_list = list_of_graph\n",
    "\n",
    "        # D ** (-1 / 2) of shape (num_of_nodes) only for one matrix as all graph got the same structure\n",
    "        graph_degrees = self.compute_degree(edges_index_list, num_of_nodes=nodes_feat_list.shape[1])\n",
    "\n",
    "        # expand degree matrix to perform Hadamard product\n",
    "        graph_degrees = graph_degrees.unsqueeze(-1)\n",
    "        # Hadamard product h_l * (D ** (-1 / 2))\n",
    "        nodes_feat_list = nodes_feat_list * graph_degrees\n",
    "\n",
    "        # aggregation \n",
    "        nodes_features_aggregated = self.aggregate_neighbors(nodes_feat_list, edges_index_list[0,:,:])\n",
    "\n",
    "        # Second Hadamard product\n",
    "        nodes_features_aggregated = nodes_features_aggregated * graph_degrees\n",
    "\n",
    "        # message passing\n",
    "        nodes_features_output = self.fc(nodes_features_aggregated)\n",
    "\n",
    "        return nodes_features_output\n",
    "        \n",
    "    \n",
    "    def aggregate_neighbors(self, nodes_feature_tens, edges_index):\n",
    "        \"\"\" \n",
    "            nodes_feature_tens: tensor of shape (batch_size, num_nodes, num_features=1)\n",
    "            edges_index: tensor of shape (2, num_edges)\n",
    "        \"\"\"\n",
    "        num_of_nodes = nodes_feature_tens.shape[1]\n",
    "        squeeze_flag = False\n",
    "        \n",
    "        if nodes_feature_tens.shape[-1] == 1:\n",
    "            nodes_feature_tens = nodes_feature_tens.squeeze(-1)\n",
    "            squeeze_flag = True\n",
    "        \n",
    "        # expand nodes_feature_tens to be able to use scatter_add_ function\n",
    "        # (batch_size, num_of_nodes) --> (batch_size, num_of_edges)\n",
    "        expanded_nodes_feature_tens = nodes_feature_tens[:,edges_index[1,:]]\n",
    "        \n",
    "        # nodes on which to aggregate\n",
    "        target_index = edges_index[0,:].unsqueeze(0)\n",
    "        \n",
    "        # shape (batch_size, num_of_edges)\n",
    "        nodes_feature_tens_output = torch.zeros_like(expanded_nodes_feature_tens, dtype=nodes_feature_tens.dtype)\n",
    "        \n",
    "        # for all node i, sum all j from i's neighborhood (in place)\n",
    "        nodes_feature_tens_output.scatter_add_(dim=1, index=target_index, src=expanded_nodes_feature_tens)\n",
    "        # crop from shape (batch_size, num_of_edges) to (batch_size, num_of_nodes)\n",
    "        nodes_feature_tens_output = nodes_feature_tens_output[:, 0:num_of_nodes]\n",
    "        \n",
    "        if squeeze_flag:\n",
    "            nodes_feature_tens_output = nodes_feature_tens_output.unsqueeze(-1)\n",
    "\n",
    "        return nodes_feature_tens_output\n",
    "    \n",
    "\n",
    "    def compute_degree(self, edges_index, num_of_nodes):\n",
    "        \"\"\"\n",
    "            Compute the degree tensor \n",
    "            /!\\ doesn't fit unconnected graph\n",
    "            edges_index: tensor of shape (batch_size, 2, number of edges) \n",
    "        \"\"\"\n",
    "        _, degree = torch.unique(edges_index[0,0,:], return_counts=True)\n",
    "        assert degree.shape[0] == num_of_nodes, f'Expected degree matrix with shape=({num_of_nodes}) got {degree.shape}.'\n",
    "        return degree ** (-1 / 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = GCN_model(1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 784, 1])\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(dataloader))\n",
    "test = model_test(data)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.random.manual_seed(123)\n",
    "\n",
    "# x = torch.randint(10, (1,10))\n",
    "\n",
    "# y, count = torch.unique(x, return_counts=True)\n",
    "\n",
    "# print(x)\n",
    "# print(count ** (-1 / 2))\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.random.manual_seed(40)\n",
    "\n",
    "# N = 3\n",
    "# B = 1\n",
    "# E = 7\n",
    "\n",
    "# h_l1 = torch.zeros((B, E, 1))\n",
    "\n",
    "# ed_idx = torch.tensor([[0, 0, 0, 1, 1, 2, 2],\n",
    "#                        [0, 1, 2, 0, 1, 0, 2]])\n",
    "\n",
    "# h_l = torch.tensor([[[10], \n",
    "#                      [20], \n",
    "#                      [30]]], dtype=h_l1.dtype)\n",
    "\n",
    "# print(\"h_l\", h_l.shape)\n",
    "# print(\"h_l1\", h_l1.shape)\n",
    "\n",
    "# expanded_h_l = h_l[:,ed_idx[1,:],:]\n",
    "# print(\"expanded_h_l\", expanded_h_l.shape)\n",
    "\n",
    "# index = ed_idx[0,:].unsqueeze(0).unsqueeze(-1)\n",
    "# print(\"index\", index.shape)\n",
    "# print(index)\n",
    "\n",
    "# print(h_l1)\n",
    "# print(expanded_h_l)\n",
    "\n",
    "# h_l1.scatter_add_(1, index=index, src=expanded_h_l)\n",
    "# h_l1 = h_l1[:,0:N,:]\n",
    "# print(h_l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "torch.random.manual_seed(42)\n",
    "\n",
    "test = torch.randint(10, (2,3,1))\n",
    "\n",
    "truc = torch.tensor([[3],\n",
    "                     [1],\n",
    "                     [2]])\n",
    "truc = truc\n",
    "print(truc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2],\n",
      "         [7],\n",
      "         [6]],\n",
      "\n",
      "        [[4],\n",
      "         [6],\n",
      "         [5]]])\n",
      "torch.Size([3, 1])\n",
      "tensor([[3],\n",
      "        [1],\n",
      "        [2]])\n",
      "tensor([[[ 6],\n",
      "         [ 7],\n",
      "         [12]],\n",
      "\n",
      "        [[12],\n",
      "         [ 6],\n",
      "         [10]]])\n"
     ]
    }
   ],
   "source": [
    "print(test)\n",
    "print(truc.shape)\n",
    "print(truc)\n",
    "print(test * truc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
